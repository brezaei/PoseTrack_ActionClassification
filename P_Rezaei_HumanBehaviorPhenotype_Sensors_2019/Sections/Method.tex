%======================
\PoseNet
Diverging from the common approach of learning spatio-temporal features from videos in action classification, pose-based action classification methods have shown promising results by providing a compact representation of the human pose evolution in videos \cite{cherian2018non, choutas2018potion, liu2018recognizing, zolfaghari2017chained}. The evolution of pose in time can be used as the only discriminating feature information for classification of human actions which involves different pose transitions. Further, this can be combined with spatio-temporal features to improve the performance of context-aware action classification in the case of more complex behaviors.

The primary task in pose-based human behavior phenotyping in untrimmed videos is locating the human actors. This requires a robust estimation and tracking of human body poses by addressing the challenges associated with long-term videos recorded for human behavior phenotyping. These challenges include partial to complete occlusion, change of scene, and camera motion. In this section, we propose an incremental multi-person pose tracking method using both time and appearance features, which will be used in later steps to generate pose evolution feature representations for action classification.