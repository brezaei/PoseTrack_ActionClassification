 %%%%%%%%%%%%%%%%%%%% Discussion
 \missclass
 As we can see in \figref{Cmat}, a significant source of error is the misclassification of $18\%$ of walking as standing. This can be attributed to two factors. Firstly, video recordings of the walking activity are performed with a frontal view of the subject, which limits the ability of pose evolution maps to capture spatial displacement features associated with walking. As a result, walking and standing look similar in the pose evolution maps. Secondly, the activity transition period from standing to walking was labeled as walking during the ground-truth annotation process. As a result, when the action classification network is applied to short action clips, those containing such transitions are likely to be misclassified as standing. Examples of the aforementioned misclassification are illustrated in \figref{missclass}. In \figref{stand} the subject takes a couple of steps to reach for a coat hanging on the rack and in \figref{transit} the subject is about to start walking from a standing position. In both cases, the ground-truth annotation was walking but the video clip was classified as standing.
 Another source of error which impacts overall performance is the error propagated from pose tracking and pose estimation stages. Pose estimation error can be tolerated to some degree by aggregating the colorized joint heatmaps in the pose evolution feature representation. However, since the output of the pose tracking is directly used for generating pose evolution maps, any error in tracking the patient throughout the video would negatively impact the action classification performance. One way to tolerate the error from pose tracking stage is to incorporate raw RGB frames as the second stream of information into the action classification and using attention maps based on the tracking outcome rather than excluding non-target persons from the input representations.  