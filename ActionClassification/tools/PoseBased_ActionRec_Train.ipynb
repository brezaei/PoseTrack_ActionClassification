{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "82a2c1c4-c554-465c-9c29-fe4d455d0514"
    }
   },
   "source": [
    "# Action Classification Using Pose-Motion feature representation\n",
    "\n",
    "On scaled pose motion representation without cropping and data augmentation\n",
    "\n",
    "Using GPU_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "8b6e7038-a603-4099-9912-e7198695d574"
    }
   },
   "outputs": [],
   "source": [
    "# import required packages and global variables\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "28873098-73b5-4bc4-9082-4399083c6091"
    }
   },
   "outputs": [],
   "source": [
    "DTYPE = np.float32\n",
    "height = 1080  # frame height in pixel\n",
    "width = 1920  # frame width in pixel\n",
    "fps = 30.0\n",
    "col_ch = 3\n",
    "sigma = 2\n",
    "resize_scale = 0.125\n",
    "sub_sample =1500\n",
    "crop = False\n",
    "classes=[\n",
    "    'Sitting',\n",
    "    'Sit-to-Stand',\n",
    "    'Standing',\n",
    "    'Walking',\n",
    "    'Stand-to-Sit'\n",
    "]\n",
    "keypoints = [\n",
    "        'nose',\n",
    "        'left_eye',\n",
    "        'right_eye',\n",
    "        'left_ear',\n",
    "        'right_ear',\n",
    "        'left_shoulder',\n",
    "        'right_shoulder',\n",
    "        'left_elbow',\n",
    "        'right_elbow',\n",
    "        'left_wrist',\n",
    "        'right_wrist',\n",
    "        'left_hip',\n",
    "        'right_hip',\n",
    "        'left_knee',\n",
    "        'right_knee',\n",
    "        'left_ankle',\n",
    "        'right_ankle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing the action classification network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_drawer will not run correctly. Please install the correct dependencies.\n",
      "Necessities for action recognition network is imported!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"caffe2.python.net_drawer\"\n"
     ]
    }
   ],
   "source": [
    "# import extra liraries required for designing the network\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "import lmdb\n",
    "import shutil\n",
    "import time\n",
    "from imageio import imread\n",
    "import caffe2.python.predictor.predictor_exporter as pe\n",
    "from caffe2.proto import caffe2_pb2\n",
    "from caffe2.python.predictor import mobile_exporter\n",
    "from caffe2.python import (\n",
    "    brew,\n",
    "    core,\n",
    "    model_helper,\n",
    "    net_drawer,\n",
    "    optimizer,\n",
    "    visualize,\n",
    "    workspace,\n",
    "    memonger\n",
    ")\n",
    "\n",
    "# If you would like to see some really detailed initializations,\n",
    "# you can change --caffe2_log_level=0 to --caffe2_log_level=-1\n",
    "core.GlobalInit(['caffe2', '--caffe2_log_level=0'])\n",
    "print(\"Necessities for action recognition network is imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN model\n",
    "Define dataset-specific parameters, and declare model training parameters.\n",
    "#### Come back and tinker with these parameters to see how it effects training and efficiency.\n",
    "base_learning_rate and weight_decay will both influence training and can be interesting to change and witness the impact on accuracy or confidence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to LMDBs\n",
    "training_lmdb_path = osp.join('/data','BehnazData','Results', 'PoseBased_ActionRec', 'training_3_2_111_lmdb')\n",
    "validation_lmdb_path = osp.join('/data', 'BehnazData', 'Results', 'PoseBased_ActionRec', 'validation_3_2_111_lmdb')\n",
    "testing_lmdb_path = osp.join('/data','BehnazData','Results', 'PoseBased_ActionRec', 'testing_3ch_lmdb')\n",
    "# Paths to the init & predict net output locations\n",
    "init_net_out = 'TuftsAction_init_net.pb'\n",
    "predict_net_out = 'TuftsAction_predict_net.pb'\n",
    "\n",
    "# Dataset specific params\n",
    "train_data_count = 4699 * 4\n",
    "validation_count = 554 * 4\n",
    "test_data_count = 624 * 4\n",
    "data_db_type = \"lmdb\"\n",
    "image_width = int(width * resize_scale)                # input image width\n",
    "image_height = int(height * resize_scale)               # input image height\n",
    "image_channels = 14 * col_ch                           # input image channels\n",
    "num_classes = 5                                        # number of action classes\n",
    "\n",
    "# Training params                   \n",
    "num_epoch = 40                                                        \n",
    "batch_size =  50        # total batch size \n",
    "validation_interval = 50                               # validate every <validation_interval> training iterations\n",
    "checkpoint_iters = 500                                 # output checkpoint db every <checkpoint_iters> iterations\n",
    "base_learning_rate = 0.01          # initial learning rate (scale with total batch size)\n",
    "step_size = 1                                     # influence the learning rate after 10 epochs\n",
    "weight_decay = 1e-3                                     # weight decay (L2 regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_folder = os.path.join('..','classification_net','SingleGPU')\n",
    "# Create root_folder if not already there\n",
    "if not os.path.isdir(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "\n",
    "# Resetting workspace with root_folder argument sets root_folder as working directory\n",
    "workspace.ResetWorkspace(root_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddInput(model, db, db_type, batch_size, noise=0):\n",
    "    # load the data\n",
    "    data_f32, label, ID = brew.db_input(\n",
    "        model,\n",
    "        blobs_out=[\"data_f32\", \"label\", \"ID\"],\n",
    "        batch_size=batch_size,\n",
    "        db=db,\n",
    "        db_type=db_type,\n",
    "    )\n",
    "    data = model.Cast(data_f32, \"data\", to=core.DataType.FLOAT)\n",
    "    Noise = model.GaussianFill([], \"noise\", shape=[batch_size, image_channels, image_height, image_width], mean=0.0,\n",
    "                              std=1.0, run_once=0)\n",
    "    data_noise = data.Add(Noise, \"data_noise\")\n",
    "    # prevent back-propagation: optional performance improvement; may not be observable at small scale\n",
    "    if noise:\n",
    "        data = model.Copy(data_noise, \"data\")\n",
    "    \n",
    "    data = model.StopGradient(data, data)\n",
    "    data_noise = model.StopGradient(data_noise, data_noise)\n",
    "    \n",
    "    \n",
    "# Helper function for maintaining the correct height and width dimensions after\n",
    "# convolutional and pooling layers downsample the input data\n",
    "def update_dims(height, width, kernel, stride, pad):\n",
    "    new_height = ((height - kernel + 2*pad)//stride) + 1\n",
    "    new_width = ((width - kernel + 2*pad)//stride) + 1\n",
    "    return new_height, new_width\n",
    "\n",
    "# Defining the action classification network model\n",
    "def Add_Action_Tufts_Model(model, num_classes, image_height, image_width, image_channels, is_test=0):\n",
    "    ################################## Block 1 ############################\n",
    "    # Convolutional layer 1\n",
    "    conv1_1 = brew.conv(model, 'data', 'conv1_1', dim_in=image_channels, dim_out=64, kernel=3, stride=2, pad=0)\n",
    "    h,w = update_dims(height=image_height, width=image_width, kernel=3, stride=2, pad=0)\n",
    "    # ReLU layer 1\n",
    "    relu1_1 = brew.relu(model, conv1_1, 'relu1_1')\n",
    "    # Batch normalization layer 1\n",
    "    bn1_1 = brew.spatial_bn(model, relu1_1, 'bn1_1', dim_in=64, epsilon=1e-3, momentum=0.1, is_test=is_test)\n",
    "    # Drop out with p=0.25\n",
    "    dropout1_1 = brew.dropout(model, bn1_1, 'dropout1_1', ratio=0.35, is_test=is_test)\n",
    "    \n",
    "    # Convolutional layer 2\n",
    "    conv1_2 = brew.conv(model, dropout1_1, 'conv1_2', dim_in=64, dim_out=64, kernel=3, stride=1, pad=0)\n",
    "    h,w = update_dims(height=h, width=w, kernel=3, stride=1, pad=0)\n",
    "    # ReLU layer 1\n",
    "    relu1_2 = brew.relu(model, conv1_2, 'relu1_2')\n",
    "    # Batch normalization layer 1\n",
    "    bn1_2 = brew.spatial_bn(model, relu1_2, 'bn1_2', dim_in=64, epsilon=1e-3, momentum=0.1, is_test=is_test)\n",
    "    # Drop out with p=0.25\n",
    "    dropout1_2 = brew.dropout(model, bn1_2, 'dropout1_2', ratio=0.35, is_test=is_test)\n",
    "    ##################################### Block 2 ##########################\n",
    "    # Convolutional layer 3\n",
    "    conv2_1 = brew.conv(model, 'dropout1_2', 'conv2_1', dim_in=64, dim_out=128, kernel=3, stride=2, pad=0)\n",
    "    h,w = update_dims(height=image_height, width=image_width, kernel=3, stride=2, pad=0)\n",
    "    # ReLU layer 1\n",
    "    relu2_1 = brew.relu(model, conv2_1, 'relu2_1')\n",
    "    # Batch normalization layer 1\n",
    "    bn2_1 = brew.spatial_bn(model, relu2_1, 'bn2_1', dim_in=128, epsilon=1e-3, momentum=0.1, is_test=is_test)\n",
    "    # Drop out with p=0.25\n",
    "    dropout2_1 = brew.dropout(model, bn2_1, 'dropout2_1', ratio=0.35, is_test=is_test)\n",
    "    \n",
    "    # Convolutional layer 4\n",
    "    conv2_2 = brew.conv(model, dropout2_1, 'conv2_2', dim_in=128, dim_out=128, kernel=3, stride=1, pad=0)\n",
    "    h,w = update_dims(height=h, width=w, kernel=3, stride=1, pad=0)\n",
    "    # ReLU layer 1\n",
    "    relu2_2 = brew.relu(model, conv2_2, 'relu2_2')\n",
    "    # Batch normalization layer 1\n",
    "    bn2_2 = brew.spatial_bn(model, relu2_2, 'bn2_2', dim_in=128, epsilon=1e-3, momentum=0.1, is_test=is_test)\n",
    "    # Drop out with p=0.25\n",
    "    dropout2_2 = brew.dropout(model, bn2_2, 'dropout2_2', ratio=0.35, is_test=is_test) \n",
    "    ##################################### Block 3 ############################\n",
    "    # Convolutional layer 5\n",
    "    conv3_1 = brew.conv(model, dropout2_2, 'conv3_1', dim_in=128, dim_out=256, kernel=3, stride=2, pad=0)\n",
    "    h,w = update_dims(height=h, width=w, kernel=3, stride=2, pad=0)\n",
    "    # ReLU layer 1\n",
    "    relu3_1 = brew.relu(model, conv3_1, 'relu3_1')\n",
    "    # Batch normalization layer 1\n",
    "    bn3_1 = brew.spatial_bn(model, relu3_1, 'bn3_1', dim_in=256, epsilon=1e-3, momentum=0.1, is_test=is_test)\n",
    "    # Drop out with p=0.25\n",
    "    dropout3_1 = brew.dropout(model, bn3_1, 'dropout3_1', ratio=0.35, is_test=is_test)\n",
    "    \n",
    "    # Convolutional layer 4\n",
    "    conv3_2 = brew.conv(model, dropout3_1, 'conv3_2', dim_in=256, dim_out=256, kernel=3, stride=1, pad=0)\n",
    "    h,w = update_dims(height=h, width=w, kernel=3, stride=1, pad=0)\n",
    "    # ReLU layer 1\n",
    "    relu3_2 = brew.relu(model, conv3_2, 'relu3_2')\n",
    "    # Batch normalization layer 1\n",
    "    bn3_2 = brew.spatial_bn(model, relu3_2, 'bn3_2', dim_in=256, epsilon=1e-3, momentum=0.1, is_test=is_test)\n",
    "    # Drop out with p=0.25\n",
    "    dropout3_2 = brew.dropout(model, bn3_2, 'dropout3_2', ratio=0.35, is_test=is_test)\n",
    "    \n",
    "    # Global average pooling\n",
    "    pool1 = brew.average_pool(model, dropout3_2, 'pool1', global_pooling=True)\n",
    "    # Fully connected layers\n",
    "    pred = brew.fc(model, pool1, 'fc1', dim_in=256, dim_out=num_classes)\n",
    "    # Softmax layer\n",
    "    softmax, loss = model.SoftmaxWithLoss([pred, 'label'], ['softmax', 'loss'])\n",
    "    brew.accuracy(model, [softmax, 'label'], 'accuracy')\n",
    "    model.net.MultiClassAccuracy([softmax, 'label'], ['accuracy_per_class', 'amount_per_class'])\n",
    "    return [loss]\n",
    "\n",
    "def AddOptimizerOps_fixsgd(model):\n",
    "    optimizer.build_sgd(\n",
    "        model,\n",
    "        base_learning_rate=0.01,\n",
    "        policy=\"fixed\",\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.004\n",
    "    )\n",
    "\n",
    "def AddOptimizerOps_adam(model):\n",
    "    # Use adam as optimization function\n",
    "    optimizer.build_adam(\n",
    "        model,\n",
    "        base_learning_rate=base_learning_rate\n",
    "#        policy=\"step\",\n",
    "#        momentum=0.9,\n",
    "#        weight_decay=0.004\n",
    "    )\n",
    "def AddOptimizerOps_sgd(model):\n",
    "    \"\"\"Add optimizer ops.\"\"\"\n",
    "    optimizer.build_sgd(model, base_learning_rate=0.01,\n",
    "                        policy='step', stepsize=1, gamma=0.999,\n",
    "                        momentum=0.9, nesterov=False)\n",
    "    \n",
    "def AddOptimizerOps_nestsgd(model):\n",
    "    brew.add_weight_decay(model, weight_decay)\n",
    "    iter = brew.iter(model, \"iter\")\n",
    "    lr = model.net.LearningRate(\n",
    "        [iter],\n",
    "        \"lr\",\n",
    "        base_lr=base_learning_rate,\n",
    "        policy=\"step\",\n",
    "        stepsize=step_size,\n",
    "        gamma=0.1,\n",
    "    )\n",
    "    for param in model.GetParams():\n",
    "        param_grad = model.param_to_grad[param]\n",
    "        param_momentum = model.param_init_net.ConstantFill(\n",
    "            [param], param + '_momentum', value=0.0\n",
    "        )\n",
    "\n",
    "        # Update param_grad and param_momentum in place\n",
    "        model.net.MomentumSGDUpdate(\n",
    "            [param_grad, param_momentum, lr, param],\n",
    "            [param_grad, param_momentum, param],\n",
    "            # almost 100% but with room to grow\n",
    "            momentum=0.9,\n",
    "            # netsterov is a defenseman for the Montreal Canadiens, but\n",
    "            # Nesterov Momentum works slightly better than standard momentum\n",
    "            nesterov=1,\n",
    "        )\n",
    "def AddAccuracy(model):\n",
    "    accuracy = brew.accuracy(model, [\"softmax\", \"label\"], \"accuracy\")\n",
    "    return accuracy\n",
    "\n",
    "def OptimizeGradientMemory(model, loss):\n",
    "    model.net._net = memonger.share_grad_blobs(\n",
    "        model.net,\n",
    "        loss,\n",
    "        set(model.param_to_grad.values()),\n",
    "        namescope=\"memaction\",\n",
    "        share_activations=False,\n",
    "        )\n",
    "def save_net(INIT_NET, PREDICT_NET, model) :\n",
    "    extra_params = []\n",
    "    extra_blobs = []\n",
    "    for blob in workspace.Blobs():\n",
    "        name = str(blob)\n",
    "        if name.endswith(\"_rm\") or name.endswith(\"_riv\"):\n",
    "            extra_params.append(name)\n",
    "            extra_blobs.append(workspace.FetchBlob(name))\n",
    "    for name, blob in zip(extra_params, extra_blobs):\n",
    "        model.params.append(name)\n",
    " \n",
    "    init_net, predict_net = mobile_exporter.Export(\n",
    "        workspace, model.net, model.params\n",
    "    )\n",
    "     \n",
    "    with open(PREDICT_NET, 'wb') as f:\n",
    "        f.write(model.net._net.SerializeToString())\n",
    "    with open(INIT_NET, 'wb') as f:\n",
    "        f.write(init_net.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding check-points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint output location:  ../classification_net/SingleGPU/2018-12-20_11-41-12\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Create uniquely named directory under root_folder to output checkpoints to\n",
    "unique_timestamp = str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "checkpoint_dir = os.path.join(root_folder, unique_timestamp)\n",
    "os.makedirs(checkpoint_dir)\n",
    "print(\"Checkpoint output location: \", checkpoint_dir)\n",
    "\n",
    "# Add checkpoints to a given model\n",
    "def AddCheckpoints(model, checkpoint_iters, db_type):\n",
    "    ITER = brew.iter(model, \"iter\")\n",
    "    model.Checkpoint([ITER] + model.params, [],\n",
    "                           db=os.path.join(unique_timestamp, \"action_tufts_checkpoint_%05d.lmdb\"),\n",
    "                           db_type=\"lmdb\", every=checkpoint_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Training net and Test net creating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_scope = {\"order\": \"NCHW\"}\n",
    "# TRAINING MODEL\n",
    "def createTrainModel(training_lmdb_path, batch_size):\n",
    "    \"\"\"Create and return a training model, complete with training ops.\"\"\"\n",
    "    train_model = model_helper.ModelHelper(name='train_net', arg_scope=arg_scope)\n",
    "    AddInput(train_model, db=training_lmdb_path, db_type=data_db_type, batch_size=batch_size, noise=1)\n",
    "    losses = Add_Action_Tufts_Model(train_model,num_classes, image_height, image_width, image_channels, is_test=0)\n",
    "    train_model.AddGradientOperators(losses)\n",
    "    AddOptimizerOps_adam(train_model)\n",
    "    AddCheckpoints(train_model, checkpoint_iters, db_type=\"lmdb\")\n",
    "    workspace.RunNetOnce(train_model.param_init_net)\n",
    "    workspace.CreateNet(train_model.net, overwrite=True)\n",
    "    return train_model\n",
    "\n",
    "# VALIDATION MODEL\n",
    "def createValidationModel(validation_lmdb_path, batch_size, with_noise=0):\n",
    "    \"\"\"Create and return a test model. Does not include training ops.\"\"\"\n",
    "    val_model = model_helper.ModelHelper(name='val_net', arg_scope=arg_scope, init_params=False)\n",
    "    AddInput(val_model, db=validation_lmdb_path, db_type=data_db_type, batch_size=batch_size, noise=with_noise)\n",
    "    losses = Add_Action_Tufts_Model(val_model,num_classes, image_height, image_width, image_channels, is_test=1)\n",
    "    workspace.RunNetOnce(val_model.param_init_net)\n",
    "    workspace.CreateNet(val_model.net, overwrite=True)\n",
    "    return val_model\n",
    "# DEPLOY MODEL\n",
    "def createDeployModel():\n",
    "    deploy_model = model_helper.ModelHelper(name=\"deploy_net\", arg_scope=arg_scope, init_params=False)\n",
    "    Add_Action_Tufts_Model(deploy_model,num_classes, image_height, image_width, image_channels, is_test=1)\n",
    "    workspace.RunNetOnce(deploy_model.param_init_net)\n",
    "    workspace.CreateNet(deploy_model.net, overwrite=True)\n",
    "    return deploy_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: GaussianFill.\n",
      "WARNING:root:You are creating an op that the ModelHelper does not recognize: GaussianFill.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# initialize the logging variables \n",
    "val_loss = np.zeros(num_epoch)\n",
    "val_total_accuracy = np.zeros(num_epoch)\n",
    "train_loss = np.zeros(num_epoch)\n",
    "train_accuracy = np.zeros(num_epoch)\n",
    "val_class_accuracy = np.zeros((num_epoch, num_classes))\n",
    "val_class_count = np.zeros(num_classes, dtype=int)\n",
    "val_count = 0\n",
    "tot_itr_count = 0\n",
    "total_time = 0\n",
    "# defining GPU device and training/ validation networks\n",
    "device = 2\n",
    "with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, device)):\n",
    "    train_model = createTrainModel(training_lmdb_path, batch_size)\n",
    "    val_model = createValidationModel(validation_lmdb_path, batch_size=batch_size, with_noise=1)\n",
    "\n",
    "# iteraring the forward/ backword pass for optimizing variables\n",
    "train_iter_per_epoch = train_data_count // batch_size\n",
    "val_iter_per_epoch = validation_count // batch_size\n",
    "# Now, we run the network (forward & backward pass)\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    t1 = time.time()\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for itr in range(1, train_iter_per_epoch+1):\n",
    "        # Stopwatch start!\n",
    "        tot_itr_count += 1\n",
    "        workspace.RunNet(train_model.net)\n",
    "        accuracies.append(workspace.FetchBlob('accuracy'))\n",
    "        losses.append(workspace.FetchBlob('loss'))\n",
    "        #if not tot_itr_count % disp_interval:\n",
    "    train_loss[val_count] = np.array(losses).mean()\n",
    "    train_accuracy[val_count] = np.array(accuracies).mean()\n",
    "    t2 = time.time()\n",
    "    dt = t2 - t1\n",
    "    total_time += dt\n",
    "    # Validate every epoch\n",
    "    print(\".... epoch:{}/{}   el_time:{}\".format(epoch, num_epoch, dt))\n",
    "    print(\"training loss:{}, training accuracy:{}\".format(train_loss[val_count], train_accuracy[val_count]))\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    accuracies_per_class = []\n",
    "    class_count = []\n",
    "    for _ in range(val_iter_per_epoch):        \n",
    "        workspace.RunNet(val_model.net)\n",
    "        losses.append(workspace.FetchBlob('loss'))\n",
    "        accuracies.append(workspace.FetchBlob('accuracy'))\n",
    "        accuracies_per_class.append(workspace.FetchBlob('accuracy_per_class'))\n",
    "        if epoch == num_epoch:\n",
    "            class_count.append(workspace.FetchBlob('amount_per_class'))\n",
    "    val_loss[val_count] = np.array(losses).mean()\n",
    "    val_total_accuracy[val_count] = np.array(accuracies).mean()\n",
    "    val_class_accuracy[val_count, :] = np.array(accuracies_per_class).mean(axis=0)\n",
    "    if epoch == num_epoch:\n",
    "        val_class_count = np.array(class_count).sum(axis=0)\n",
    "    print(\"Validation Loss:{}, Validation total accuracy:{}, Per class validation accuracy:{}\"\n",
    "          .format(val_loss[val_count],val_total_accuracy[val_count], val_class_accuracy[val_count, :] ))\n",
    "    val_count += 1\n",
    "\n",
    "print(\"Per class data count: Sitting={}, Sit-to-Stand={}, Standing={}, Walking={}, Stand-to-Sit={}\"\n",
    "      .format(val_class_count[0], val_class_count[1],\n",
    "            val_class_count[2], val_class_count[3],\n",
    "            val_class_count[4]))\n",
    "print('total elapsed time is {}'.format(total_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "plt.title(\"Training Loss vs. Validation Accuracy and loss\")\n",
    "plt.plot(range(1, num_epoch+1), train_loss, 'b')\n",
    "plt.plot(range(1, num_epoch+1), val_loss, 'c')\n",
    "plt.plot(range(1, num_epoch+1), train_accuracy, 'm')\n",
    "plt.plot(range(1, num_epoch+1), val_total_accuracy, 'r')\n",
    "plt.xlabel(\"Training epoch\")\n",
    "plt.legend(('Training Loss', 'Validation loss','Training accuracy','Validation accuracy'), loc='upper right')\n",
    "plt.xlim((0,num_epoch))\n",
    "plt.ylim((0, 1.5))\n",
    "plt.grid(b=1,which='major', linestyle='-', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "test_batch_size = 1\n",
    "# confusion matrix\n",
    "cmat = np.zeros((5,5))\n",
    "with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, device)):\n",
    "    test_model = createValidationModel(testing_lmdb_path, batch_size=test_batch_size, with_noise=0)\n",
    "# iteraring the forward/ backword pass for optimizing variables\n",
    "test_iter_per_epoch = test_data_count // test_batch_size\n",
    "# Now, we run the network (forward & backward pass)\n",
    "losses = []\n",
    "accuracies = []\n",
    "accuracies_per_class = []\n",
    "class_count = []\n",
    "pred = []\n",
    "true = []\n",
    "Ids = []\n",
    "t0 = time.time()\n",
    "for _ in range(test_iter_per_epoch):        \n",
    "    workspace.RunNet(test_model.net)\n",
    "#    losses.append(workspace.FetchBlob('loss'))\n",
    "    accuracies.append(workspace.FetchBlob('accuracy'))\n",
    "#    accuracies_per_class.append(workspace.FetchBlob('accuracy_per_class'))\n",
    "    class_count.append(workspace.FetchBlob('amount_per_class'))\n",
    "    results = workspace.FetchBlob('softmax')[0]\n",
    "    label = workspace.FetchBlob('label')[0]\n",
    "    Ids.append(workspace.FetchBlob(\"ID\"))\n",
    "    max_index, max_value = max(enumerate(results), key=operator.itemgetter(1))\n",
    "    pred.append(classes[max_index])\n",
    "    true.append(label)\n",
    "    # Update confusion matrix\n",
    "    cmat[label,max_index] += 1\n",
    "t1 = time.time()\n",
    "dt = t1 - t0\n",
    "#test_loss = np.array(losses).mean()\n",
    "test_total_accuracy = np.array(accuracies).mean()\n",
    "test_class_accuracy = np.diag(cmat)/np.sum(cmat, axis=1)\n",
    "test_class_count = np.array(class_count).sum(axis=0)\n",
    "print(\"Test total accuracy:{}, Per class test accuracy:{}\"\n",
    "        .format(test_total_accuracy, test_class_accuracy))\n",
    "\n",
    "print(\"Per class data count: Sitting={}, Sit-to-Stand={}, Standing={}, Walking={}, Stand-to-Sit={}\"\n",
    "      .format(test_class_count[0], test_class_count[1],\n",
    "            test_class_count[2], test_class_count[3],\n",
    "            test_class_count[4]))\n",
    "print('total elapsed time is {}'.format(dt))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.tight_layout()\n",
    "ax = fig.add_subplot(111)\n",
    "res = ax.imshow(cmat, cmap=plt.cm.summer, interpolation='nearest')\n",
    "width, height = cmat.shape\n",
    "for x in xrange(width):\n",
    "    for y in xrange(height):\n",
    "        ax.annotate(str(cmat[x,y]), xy=(y, x),horizontalalignment='center',verticalalignment='center')\n",
    "plt.xticks(range(width), classes, rotation=0)\n",
    "plt.yticks(range(height), classes, rotation=0)\n",
    "ax.set_xlabel('Predicted Class')\n",
    "ax.set_ylabel('True Class')\n",
    "plt.title('Confusion Matrix for test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int(Ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the prediction results in a text file\n",
    "pred_file = os.path.join(checkpoint_dir, 'test_prediction.txt')\n",
    "testing_labels_path = osp.join(testing_lmdb_path, 'valid_data_list.txt')\n",
    "labels_handler = open(testing_labels_path, \"r\")\n",
    "lines = labels_handler.readlines()\n",
    "with open(pred_file, 'wb') as f:\n",
    "    f.write(\" clip address, true class, predicted class \\n\")\n",
    "    for j in range(len(pred)):\n",
    "        indx = int(Ids[j]-1)\n",
    "        f.write(lines[indx].rstrip()+'\\t'+ classes[true[j]] + '\\t'+ pred[j] + '\\n')\n",
    "        \n",
    "labels_handler.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_tion_im = workspace.FetchBlob('data')\n",
    "print(classes[int(workspace.FetchBlob('label'))])\n",
    "\n",
    "po_tion_im = po_tion_im[0,:,:,:]\n",
    "print(po_tion_im.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run init net and create main net\n",
    "#workspace.RunNetOnce(deploy_model.param_init_net)\n",
    "#workspace.CreateNet(deploy_model.net, overwrite=True)\n",
    "with core.DeviceScope(core.DeviceOption(caffe2_pb2.CUDA, device)):\n",
    "    deploy_model = createDeployModel()\n",
    "\n",
    "# Locations of output files\n",
    "full_init_net_out = os.path.join(checkpoint_dir, init_net_out)\n",
    "full_predict_net_out = os.path.join(checkpoint_dir, predict_net_out)\n",
    "\n",
    "save_net(full_init_net_out, full_predict_net_out, deploy_model)\n",
    "print(\"Model saved as \" + full_init_net_out + \" and \" + full_predict_net_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your network does not have batch normalization just use the following script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mobile_exporter's Export function to acquire init_net and predict_net\n",
    "#init_net, predict_net = mobile_exporter.Export(workspace, deploy_model.net, deploy_model.params)\n",
    "\n",
    "# Locations of output files\n",
    "#full_init_net_out = os.path.join(checkpoint_dir, init_net_out)\n",
    "#full_predict_net_out = os.path.join(checkpoint_dir, predict_net_out)\n",
    "\n",
    "# Simply write the two nets to file\n",
    "#with open(full_init_net_out, 'wb') as f:\n",
    "#    f.write(init_net.SerializeToString())\n",
    "#with open(full_predict_net_out, 'wb') as f:\n",
    "#    f.write(predict_net.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
